{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import func\n",
    "import phantom\n",
    "import KTCFwd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    ##Neural Network\n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "        'loss function'\n",
    "        self.loss_function = nn.CrossEntropyLoss() # Change to the real loss function that we are given\n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)]) \n",
    "        self.iter = 0\n",
    "        'Xavier Normal Initialization'\n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            \n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            \n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)   \n",
    "    'foward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        a = x.float()\n",
    "        for i in range(len(layers)-2):  \n",
    "            z = self.linears[i](a)              \n",
    "            a = self.activation(z)    \n",
    "        a = self.linears[-1](a)\n",
    "        return a\n",
    "    \n",
    "    def loss_BC(self,x,y):\n",
    "                \n",
    "        loss_u = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_u\n",
    "    \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.loss(X_train_Nu, U_train_Nu, X_train_Nf)\n",
    "        \n",
    "        loss.backward()\n",
    "                \n",
    "        self.iter += 1\n",
    "        \n",
    "        if self.iter % 100 == 0:\n",
    "\n",
    "            error_vec, _ = PINN.test()\n",
    "        \n",
    "            print(loss,error_vec)\n",
    "\n",
    "        return loss  \n",
    "    \n",
    "    'test neural network'\n",
    "    def test(self):\n",
    "                \n",
    "        u_pred = self.forward(X_test)\n",
    "        \n",
    "        error_vec = torch.linalg.norm((u-u_pred),2)/torch.linalg.norm(u,2)        # Relative L2 Norm of the error (Vector)\n",
    "        \n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "        \n",
    "        u_pred = np.reshape(u_pred,(256,100),order='F')\n",
    "                \n",
    "        return error_vec, u_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2356])\n",
      "FCN(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2356, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=65536, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'TrainingData'\n",
    "groundtruth_folder = 'GroundTruths'\n",
    "\n",
    "data_number = 1\n",
    "mat_dict = sp.io.loadmat(input_folder + '/ref.mat') #load the reference data\n",
    "mat_files = glob.glob(input_folder + '/data*.mat') # load the real data\n",
    "reference = mat_dict['Uelref']\n",
    "mat_dict2 = sp.io.loadmat(mat_files[data_number-1])\n",
    "Uel = mat_dict2[\"Uel\"]\n",
    "\n",
    "x = torch.from_numpy(Uel.squeeze())\n",
    "\n",
    "print(x.shape) # 1 data point\n",
    "\n",
    "input_size = len(x)\n",
    "layers = np.array([input_size,256,256*256])\n",
    "PINN = FCN(layers)\n",
    "print(PINN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0219,  0.0049,  0.0181,  ..., -0.0660, -0.0075,  0.0069],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINN.forward(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
